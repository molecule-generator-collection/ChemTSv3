{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add path (for local)\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
            "/opt/anaconda3/envs/v3-forge/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from typing import Optional\n",
        "from guacamol.goal_directed_generator import GoalDirectedGenerator\n",
        "from guacamol.scoring_function import ScoringFunction\n",
        "from guacamol.assess_goal_directed_generation import assess_goal_directed_generation\n",
        "from rdkit import Chem\n",
        "\n",
        "from reward import MolReward\n",
        "from utils import conf_from_yaml, generator_from_conf\n",
        "\n",
        "class GuacaMolReward(MolReward):\n",
        "    def __init__(self, scoring_function: ScoringFunction):    \n",
        "        self.scoring_function = scoring_function\n",
        "        \n",
        "    # implement\n",
        "    def mol_objective_functions(self):\n",
        "        def raw_score(mol):\n",
        "            smiles = Chem.MolToSmiles(mol)\n",
        "            return self.scoring_function.score(smiles)\n",
        "\n",
        "        return [raw_score]\n",
        "\n",
        "    # implement\n",
        "    def reward_from_objective_values(self, objective_values):\n",
        "        score = objective_values[0]\n",
        "        return score\n",
        "\n",
        "class V3DeNovoGenerator(GoalDirectedGenerator):\n",
        "    def __init__(self, conf):\n",
        "        self.conf = conf\n",
        "        self.generator = generator_from_conf(self.conf)\n",
        "\n",
        "    # implement\n",
        "    def generate_optimized_molecules(self, scoring_function: ScoringFunction, number_molecules: int, starting_population: Optional[list[str]] = None) -> list[str]:\n",
        "        self.generator.reward = GuacaMolReward(scoring_function=scoring_function)\n",
        "        self.generator.generate(max_generations=self.conf.get(\"max_generations\"), time_limit=self.conf.get(\"time_limit\"))\n",
        "        return self.generator.generated_keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from guacamol.assess_goal_directed_generation import _evaluate_goal_directed_benchmarks\n",
        "from guacamol.benchmark_suites import goal_directed_benchmark_suite\n",
        "from guacamol.goal_directed_benchmark import GoalDirectedBenchmarkResult\n",
        "\n",
        "def assess(goal_directed_molecule_generator: GoalDirectedGenerator, benchmark_version='v1') -> list[GoalDirectedBenchmarkResult]:\n",
        "\n",
        "    benchmarks = goal_directed_benchmark_suite(version_name=benchmark_version)\n",
        "\n",
        "    results = _evaluate_goal_directed_benchmarks(\n",
        "        goal_directed_molecule_generator=goal_directed_molecule_generator,\n",
        "        benchmarks=benchmarks)\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from utils import generator_from_conf, conf_from_yaml\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "yaml_path = \"config/optuna_guacamol.yaml\"\n",
        "v1_benchmark_names = ['C11H24', 'C7H8N2O2', 'C9H10N2O2PF2Cl', 'Cobimetinib MPO', 'Osimertinib MPO', 'Fexofenadine MPO', 'Physchem MPO', 'Ranolazine MPO', 'Celecoxib rediscovery', 'Troglitazone rediscovery', 'Thiothixene rediscovery', 'Aripiprazole similarity', 'Albuterol similarity', 'Mestranol similarity', 'logP (target: -1.0)', 'logP (target: 8.0)', 'TPSA (target: 150.0)', 'CNS MPO', 'QED', 'Median molecules 1']\n",
        "\n",
        "conf = conf_from_yaml(yaml_path, repo_root)\n",
        "name = conf.get(\"study_name\")\n",
        "n_trials = conf.get(\"n_trials\")\n",
        "\n",
        "def objective(trial: optuna.Trial):\n",
        "    conf = conf_from_yaml(yaml_path, repo_root)\n",
        "\n",
        "    conf[\"max_generations\"] = trial.suggest_categorical(\"max_generations\", [25000, 20000, 10000, 8192, 5000])    \n",
        "\n",
        "    conf.setdefault(\"transition_args\", {})\n",
        "    conf[\"transition_args\"][\"sharpness\"] = trial.suggest_float(\"sharpness\", 0.8, 1.1)\n",
        "    conf[\"transition_args\"][\"top_p\"] = trial.suggest_float(\"top_p\", 0.993, 0.999)\n",
        "    \n",
        "    conf.setdefault(\"policy_args\", {})\n",
        "    conf[\"policy_args\"][\"c\"] = trial.suggest_float(\"c\", 0.05, 0.4)\n",
        "    conf[\"policy_args\"][\"best_rate\"] = trial.suggest_float(\"best_rate\", 0, 1)\n",
        "    conf[\"policy_args\"][\"prior\"] = trial.suggest_float(\"prior\", 0.5, 1.4)\n",
        "    conf[\"policy_args\"][\"prior_weight\"] = trial.suggest_int(\"prior_weight\", 0, 2)\n",
        "    conf[\"policy_args\"][\"max_prior\"] = trial.suggest_float(\"max_prior\", 0.2, 0.9)\n",
        "\n",
        "    conf.setdefault(\"generator_args\", {})\n",
        "    conf[\"generator_args\"][\"eval_width\"] = trial.suggest_int(\"eval_width\", 1, 40)\n",
        "    conf[\"generator_args\"][\"n_evals\"] = trial.suggest_int(\"n_evals\", 1, 10)\n",
        "    conf[\"generator_args\"][\"n_tries\"] = trial.suggest_int(\"n_tries\", 1, 3)\n",
        "    \n",
        "    gdg = V3DeNovoGenerator(conf)\n",
        "    gdg.generator.logger.info(f\"params={trial.params}\")\n",
        "    \n",
        "    scores = assess(gdg)\n",
        "    scores = [result.score for result in scores]\n",
        "    \n",
        "    for i, score in enumerate(scores):\n",
        "        trial.set_user_attr(v1_benchmark_names[i], score)\n",
        "    sum_score = sum(scores)\n",
        "    trial.set_user_attr(\"sum_score\", sum_score)\n",
        "\n",
        "    print_trial(trial)\n",
        "    \n",
        "    return sum_score\n",
        "    \n",
        "def print_trial(trial: optuna.Trial):\n",
        "    print(f\"Trial {trial.number}: attrs={trial.user_attrs}, params={trial.params}\")\n",
        "    \n",
        "def print_best_trials(study: optuna.Study):\n",
        "    print(\"Optuna trials completed.\")\n",
        "    print(\"------ Best trials -----\")\n",
        "    best_trials = sorted([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE], key=lambda t: t.value, reverse=True)[:5]\n",
        "    for t in best_trials:\n",
        "        print_trial(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start search\n",
        "storage = \"sqlite:///optuna/\" + name + \".db\"\n",
        "sampler = sampler=optuna.samplers.TPESampler(multivariate=True, group=True)\n",
        "# sampler = optuna.samplers.GPSampler(deterministic_objective=False) # better if not using pruner?\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=0, interval_steps=1)\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=name, storage=storage, sampler=sampler, pruner=pruner)\n",
        "study.enqueue_trial({'sharpness': 0.98, 'top_p': 0.998, 'c': 0.17, 'best_rate': 0.95, 'prior': 1.0, 'prior_weight': 2, 'max_prior': 0.3, 'eval_width': 16, 'n_evals': 5, 'n_tries': 3})\n",
        "study.optimize(objective, n_trials=n_trials)\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# continue search\n",
        "study = optuna.study.load_study(study_name=\"d_score_200000\", storage=\"sqlite:///optuna/d_score_200000.db\")\n",
        "study.optimize(objective, n_trials=300)\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add parameters\n",
        "study = optuna.study.load_study(study_name=\"d_score_200000\", storage=\"sqlite:///sqlite:///optuna/d_score_200000.db\")\n",
        "\n",
        "sampler = sampler=optuna.samplers.TPESampler(multivariate=True, group=True)\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=0, interval_steps=1)\n",
        "new_storage=\"sqlite:///optuna/d_score_200000_new.db\"\n",
        "study_with_new_param = optuna.create_study(direction=\"maximize\", study_name=name, storage=new_storage, sampler=sampler, pruner=pruner)\n",
        "\n",
        "for trial in study.trials:\n",
        "    params = trial.params\n",
        "    dists = trial.distributions\n",
        "\n",
        "    params[\"cut_failed_child\"] = False\n",
        "    dists[\"cut_failed_child\"] = optuna.distributions.CategoricalDistribution([True, False])\n",
        "\n",
        "    trial.params = params\n",
        "    trial.distributions = dists\n",
        "\n",
        "    study_with_new_param.add_trial(trial)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
