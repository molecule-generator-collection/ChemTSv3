{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add path (for local)\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transition import RNNLanguageModel\n",
        "\n",
        "#ref: https://discuss.pytorch.org/t/loading-tensorflow-grucell-weights-into-pytorch/113216/4\n",
        "\n",
        "def convert_input_kernel(kernel):\n",
        "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
        "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
        "    \n",
        "def convert_recurrent_kernel(kernel):\n",
        "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
        "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
        "\n",
        "def convert_bias(bias):\n",
        "    bias = bias.reshape(2, 3, -1) \n",
        "    return bias[:, [1, 0, 2], :].reshape((2, -1))\n",
        "\n",
        "def copy_tf_gru_weights(p_rnn_layer, tf_kernel, tf_recurrent, tf_bias, layer_idx=0):\n",
        "    suffix = f\"_l{layer_idx}\"\n",
        "    with torch.no_grad():\n",
        "        getattr(p_rnn_layer, f\"weight_ih{suffix}\").copy_(torch.from_numpy(convert_input_kernel(tf_kernel)))\n",
        "        getattr(p_rnn_layer, f\"weight_hh{suffix}\").copy_(torch.from_numpy(convert_recurrent_kernel(tf_recurrent)))\n",
        "        getattr(p_rnn_layer, f\"bias_ih{suffix}\").copy_(torch.from_numpy(convert_bias(tf_bias)[0]))\n",
        "        getattr(p_rnn_layer, f\"bias_hh{suffix}\").copy_(torch.from_numpy(convert_bias(tf_bias)[1]))\n",
        "\n",
        "def load_tf_weights_npz_to_gru_model(p_model, npz_path=\"tf_weights.npz\"):\n",
        "    data = np.load(npz_path)\n",
        "\n",
        "    weights = [data[f'arr_{i}'] for i in range(len(data.files))]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p_model.embed.weight.copy_(torch.from_numpy(weights[0]))\n",
        "        copy_tf_gru_weights(p_model.rnn, weights[1], weights[2], weights[3], layer_idx=0)\n",
        "        copy_tf_gru_weights(p_model.rnn, weights[4], weights[5], weights[6], layer_idx=1)\n",
        "        p_model.fc.weight.copy_(torch.from_numpy(weights[7].T))\n",
        "        p_model.fc.bias.copy_(torch.from_numpy(weights[8]))\n",
        "        \n",
        "model = RNNLanguageModel(vocab_size=64, embed_size=64, hidden_size=256, num_layers=2, rnn_type=\"GRU\", dropout=0.2, pad_id=0)\n",
        "load_tf_weights_npz_to_gru_model(model, \"tf_weights.npz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from rdkit import RDLogger\n",
        "from language import SMILES\n",
        "from node import MolSentenceNode\n",
        "from transition import RNNTransition\n",
        "from filter import ValidityFilter\n",
        "from generator import RandomGenerator\n",
        "from utils import add_sep\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "tokens = ['<EOS>', '#', '<BOS>', '(', ')', '-', '/', '1', '2', '3', '4', '5', '6', '7', '8', '=', 'Br', 'C', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', '[C@@H]', '[C@@]', '[C@H]', '[C@]', '[CH-]', '[CH2-]', '[N+]', '[N-]', '[NH+]', '[NH-]', '[NH2+]', '[NH3+]', '[O+]', '[O-]', '[OH+]', '[P+]', '[P@@H]', '[P@@]', '[P@]', '[PH+]', '[PH2]', '[PH]', '[S+]', '[S-]', '[S@@+]', '[S@@]', '[S@]', '[SH+]', '[n+]', '[n-]', '[nH+]', '[nH]', '[o+]', '[s+]', '\\\\', 'c', 'n', 'o', 's', \"<PAD>\", \"<UNKNOWN>\"]\n",
        "lang = SMILES.load_tokens_list(tokens)\n",
        "transition = RNNTransition(lang=lang, model=model, device=\"cpu\", top_p=1)\n",
        "transition.device = \"cpu\"\n",
        "root = MolSentenceNode.node_from_string(lang=lang, string=\"CCC\")\n",
        "filters = [ValidityFilter()]\n",
        "generator = RandomGenerator(root=root, transition=transition, filters=filters, info_interval=1)\n",
        "\n",
        "for a, n, p in transition.transitions(root):\n",
        "    print(str(n), p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator.generate(max_generations=1000)\n",
        "generator.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lang.save(\"ported.lang\")\n",
        "model.save(\"ported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
