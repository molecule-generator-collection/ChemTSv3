{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fujii/anaconda3/envs/v3-forge/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language\n",
        "from node import MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "yaml_path = \"config/optuna_generation.yaml\"\n",
        "\n",
        "with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "    conf = yaml.safe_load(f)\n",
        "transition_args = conf.get(\"transition_args\", {})\n",
        "model_dir = os.path.join(repo_root, transition_args.pop(\"model_dir\"))\n",
        "lang_path = conf.get(\"lang_path\")\n",
        "if lang_path is None:\n",
        "    lang_name = os.path.basename(os.path.normpath(model_dir)) + \".lang\"\n",
        "    lang_path = add_sep(model_dir) + lang_name\n",
        "lang = Language.load(lang_path)\n",
        "policy_args = conf.get(\"policy_args\", {})\n",
        "reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "filter_settings = conf.get(\"filters\", [])\n",
        "filters = []\n",
        "for s in filter_settings:\n",
        "    filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "    filters.append(filter_class(**s))\n",
        "generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "def objective(trial):\n",
        "    transition_args[\"top_p\"] = 1 - trial.suggest_loguniform(\"1-top_p\", 0.003, 0.007)\n",
        "    transition_args[\"power\"] = trial.suggest_uniform(\"power\", 0.7, 1.3)\n",
        "    # transition_args[\"temperature\"] = trial.suggest_uniform(\"temperature\", 0.7, 1.2)\n",
        "    # policy_class = trial.suggest_categorical(\"policy_class\", [\"UCB\", \"PUCT\"])\n",
        "    policy_class = \"UCB1\"\n",
        "    policy_args[\"c\"] = trial.suggest_uniform(\"c\", 0.01, 1)\n",
        "    policy_args[\"best_rate\"] = trial.suggest_uniform(\"best_rate\", 0, 1)\n",
        "    # generator_args[\"filtered_reward\"] = trial.suggest_uniform(\"filtered_reward\", -1, 0.2)\n",
        "    generator_args[\"rollout_width\"] = trial.suggest_int(\"rollout_width\", 1, 40)\n",
        "    # generator_args[\"allow_rollout_overlaps\"] = trial.suggest_categorical(\"allow_rollout_overlaps\", [True, False])\n",
        "    generator_args[\"n_rollouts\"] = trial.suggest_int(\"n_rollouts\", 1, 10)\n",
        "    generator_args[\"n_tries\"] = trial.suggest_int(\"n_tries\", 1, 3)\n",
        "    generator_args[\"terminal_reward\"] = trial.suggest_categorical(\"terminal_reward\", [\"ignore\", -1])\n",
        "    generator_args[\"remove_failed_child\"] = trial.suggest_categorical(\"remove_failed_child\", [True, False])\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    console_level = logging.ERROR\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, console_level=console_level, file_level=file_level)\n",
        "    logger.info(\"params:\" + str(trial.params))\n",
        "\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(model_dir=model_dir, lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "    \n",
        "    policy_class = class_from_package(\"policy\", policy_class)\n",
        "    policy = policy_class(**policy_args)\n",
        "    generator_args[\"policy\"] = policy\n",
        "        \n",
        "    root = MolSentenceNode.bos_node(lang, device=conf.get(\"device\")) # TODO: change after root node generalization\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "    \n",
        "    max_generations, time_limit = conf.get(\"max_generations\"), conf.get(\"time_limit\")\n",
        "    n_steps, best_reward_rate, mean_reward_window = conf.get(\"n_steps\"), conf.get(\"best_reward_rate\"), conf.get(\"mean_reward_window\")\n",
        "    \n",
        "    for i in range(0, n_steps):\n",
        "        generator.generate(max_generations=max_generations / n_steps, time_limit=time_limit / n_steps)\n",
        "        mean_reward = generator.mean_reward(window=mean_reward_window)\n",
        "        intermediate_value = (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "        trial.report(intermediate_value, i)\n",
        "        if trial.should_prune():\n",
        "            print(f\"Trial {trial.number} - Step {i}: mean_reward={mean_reward:.3f}, best_reward={generator.best_reward:.3f}, params={trial.params}\")\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(\"mean_reward\", mean_reward)\n",
        "    trial.set_user_attr(\"best_reward\", generator.best_reward)\n",
        "    print(f\"Trial {trial.number}: mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}\")\n",
        "    generator.analyze()\n",
        "    generator.plot(**conf.get(\"plot_args\"))\n",
        "    return (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "    \n",
        "def print_trial(trial: optuna.Trial):\n",
        "    print(f\"Trial {trial.number} score={trial.value:.3f}, mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}, params={trial.params}\")\n",
        "    \n",
        "def print_best_trials(study: optuna.Study):\n",
        "    print(\"Optuna trials completed.\")\n",
        "    print(\"------ Best trials -----\")\n",
        "    best_trials = sorted([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE], key=lambda t: t.value, reverse=True)[:5]\n",
        "    for t in best_trials:\n",
        "        print_trial(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fujii/anaconda3/envs/v3-forge/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/home/fujii/anaconda3/envs/v3-forge/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "[I 2025-06-24 14:41:27,931] A new study created in RDB with name: d_score_200000\n"
          ]
        }
      ],
      "source": [
        "# start search\n",
        "name = conf.get(\"study_name\")\n",
        "storage = \"sqlite:///optuna/\" + name + \".db\"\n",
        "sampler = sampler=optuna.samplers.TPESampler(multivariate=True, group=True)\n",
        "# sampler = optuna.samplers.GPSampler(deterministic_objective=False) # better if not using pruner?\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=0, interval_steps=1)\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=name, storage=storage, sampler=sampler, pruner=pruner)\n",
        "study.enqueue_trial({\"1-top_p\": 0.005, \"power\": 1.0, \"c\": 0.2, \"best_rate\": 0.5, \"rollout_width\": 1, \"n_rollouts\": 1, \"n_tries\": 1, \"terminal_reward\": \"ignore\", \"remove_failed_child\": False})\n",
        "study.enqueue_trial({\"1-top_p\": 0.005, \"power\": 1.0, \"c\": 0.2, \"best_rate\": 0.5, \"rollout_width\": 3, \"n_rollouts\": 3, \"n_tries\": 1, \"terminal_reward\": -1, \"remove_failed_child\": True})\n",
        "study.enqueue_trial({\"1-top_p\": 0.005, \"power\": 1.2, \"c\": 0.2, \"best_rate\": 0.5, \"rollout_width\": 9, \"n_rollouts\": 1, \"n_tries\": 1, \"terminal_reward\": -1, \"remove_failed_child\": False})\n",
        "study.optimize(objective, n_trials=conf.get(\"n_trials\"))\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# continue search\n",
        "study = optuna.study.load_study(study_name=\"d_score_200000\", storage=\"sqlite:///optuna/d_score_200000.db\")\n",
        "study.optimize(objective, n_trials=300)\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add parameters\n",
        "study = optuna.study.load_study(study_name=\"d_score_200000\", storage=\"sqlite:///sqlite:///optuna/d_score_200000.db\")\n",
        "\n",
        "name = conf.get(\"study_name\")\n",
        "sampler = sampler=optuna.samplers.TPESampler(multivariate=True, group=True)\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=0, interval_steps=1)\n",
        "new_storage=\"sqlite:///optuna/d_score_200000_new.db\"\n",
        "study_with_new_param = optuna.create_study(direction=\"maximize\", study_name=name, storage=new_storage, sampler=sampler, pruner=pruner)\n",
        "\n",
        "for trial in study.trials:\n",
        "    params = trial.params\n",
        "    dists = trial.distributions\n",
        "\n",
        "    params[\"remove_failed_child\"] = False\n",
        "    dists[\"remove_failed_child\"] = optuna.distributions.CategoricalDistribution([True, False])\n",
        "\n",
        "    trial.params = params\n",
        "    trial.distributions = dists\n",
        "\n",
        "    study_with_new_param.add_trial(trial)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
