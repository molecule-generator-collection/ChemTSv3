{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language\n",
        "from node import MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "yaml_path = \"config/optuna_generation.yaml\"\n",
        "\n",
        "with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "    conf = yaml.safe_load(f)\n",
        "transition_args = conf.get(\"transition_args\", {})\n",
        "model_dir = os.path.join(repo_root, transition_args.pop(\"model_dir\"))\n",
        "lang_path = conf.get(\"lang_path\")\n",
        "if lang_path is None:\n",
        "    lang_name = os.path.basename(os.path.normpath(model_dir)) + \".lang\"\n",
        "    lang_path = add_sep(model_dir) + lang_name\n",
        "lang = Language.load(lang_path)\n",
        "policy_args = conf.get(\"policy_args\", {})\n",
        "reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "filter_settings = conf.get(\"filters\", [])\n",
        "filters = []\n",
        "for s in filter_settings:\n",
        "    filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "    filters.append(filter_class(**s))\n",
        "generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "def objective(trial):\n",
        "    transition_args[\"top_p\"] = 1 - trial.suggest_loguniform(\"1-top_p\", 0.001, 0.02)\n",
        "    transition_args[\"temperature\"] = trial.suggest_uniform(\"temperature\", 0.7, 1.2)\n",
        "    # policy_class = trial.suggest_categorical(\"policy_class\", [\"UCB\", \"PUCT\"])\n",
        "    policy_class = \"UCB\"\n",
        "    policy_args[\"c\"] = trial.suggest_uniform(\"c\", 0.01, 1)\n",
        "    policy_args[\"best_rate\"] = trial.suggest_uniform(\"best_rate\", 0, 1)\n",
        "    generator_args[\"filtered_reward\"] = trial.suggest_uniform(\"filtered_reward\", -1, 0.2)\n",
        "    generator_args[\"rollout_width\"] = trial.suggest_int(\"rollout_width\", 1, 40)\n",
        "    # generator_args[\"allow_rollout_overlaps\"] = trial.suggest_categorical(\"allow_rollout_overlaps\", [True, False])\n",
        "    generator_args[\"n_rollouts\"] = trial.suggest_int(\"n_rollouts\", 1, 10)\n",
        "    generator_args[\"n_tries\"] = trial.suggest_int(\"n_tries\", 1, 5)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    console_level = logging.ERROR\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, console_level=console_level, file_level=file_level)\n",
        "    logger.info(\"params:\" + str(trial.params))\n",
        "\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(model_dir=model_dir, lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "    \n",
        "    policy_class = class_from_package(\"policy\", policy_class)\n",
        "    policy = policy_class(**policy_args)\n",
        "    generator_args[\"policy\"] = policy\n",
        "        \n",
        "    root = MolSentenceNode.bos_node(lang, device=conf.get(\"device\")) # TODO: change after root node generalization\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "    \n",
        "    max_generations, time_limit = conf.get(\"max_generations\"), conf.get(\"time_limit\")\n",
        "    n_steps, best_reward_rate, mean_reward_window = conf.get(\"n_steps\"), conf.get(\"best_reward_rate\"), conf.get(\"mean_reward_window\")\n",
        "    \n",
        "    for i in range(0, n_steps):\n",
        "        generator.generate(max_generations=max_generations / n_steps, time_limit=time_limit / n_steps)\n",
        "        mean_reward = generator.mean_reward(window=mean_reward_window)\n",
        "        intermediate_value = (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "        trial.report(intermediate_value, i)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    trial.set_user_attr(\"mean_reward\", mean_reward)\n",
        "    trial.set_user_attr(\"best_reward\", generator.best_reward)\n",
        "    print(f\"Trial {trial.number} mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}\")\n",
        "    generator.plot(**conf.get(\"plot_args\"))\n",
        "    return (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "\n",
        "def log_callback(study: optuna.Study, trial: optuna.Trial):\n",
        "    val = trial.value\n",
        "    print_trial(trial)\n",
        "    \n",
        "def print_trial(trial: optuna.Trial):\n",
        "    print(f\"Trial {trial.number} score={trial.value:.3f}, mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}, params={trial.params}\")\n",
        "    \n",
        "def print_best_trials(study: optuna.Study):\n",
        "    print(\"Optuna trials completed.\")\n",
        "    print(\"------ Best trials -----\")\n",
        "    best_trials = sorted([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE], key=lambda t: t.value, reverse=True)[:5]\n",
        "    for t in best_trials:\n",
        "        print_trial(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# start search\n",
        "name = conf.get(\"study_name\")\n",
        "storage = \"sqlite:///generation_result/optuna_\" + name + \".db\"\n",
        "sampler = sampler=optuna.samplers.TPESampler(multivariate=True, group=True)\n",
        "# sampler = optuna.samplers.GPSampler(deterministic_objective=False) # better if not using pruner?\n",
        "pruner = optuna.pruners.MedianPruner(n_startup_trials=4, n_warmup_steps=0, interval_steps=1)\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=name, storage=storage, sampler=sampler, pruner=pruner)\n",
        "study.enqueue_trial({\"1-top_p\": 0.002598657659083491, \"temperature\": 0.8808830873822, \"c\": 0.33646460754494056, \"best_rate\": 0.6042315721899106, \"filtered_reward\": 0.16523029006562534, \"rollout_width\": 15, \"n_rollouts\": 5, \"n_tries\": 2})\n",
        "study.enqueue_trial({\"1-top_p\": 0.005, \"temperature\": 1, \"c\": 0.2, \"best_rate\": 0.5, \"filtered_reward\": 0, \"rollout_width\": 1, \"n_rollouts\": 1, \"n_tries\": 1})\n",
        "study.optimize(objective, n_trials=conf.get(\"n_trials\")) # callbacks=[log_callback]\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 109 score=0.439, mean_reward=0.374, best_reward=0.590, params={'1-top_p': 0.0023156226560240205, 'temperature': 0.757620781022158, 'policy_class': 'UCB', 'c': 0.2893515104231392, 'best_rate': 0.5760035886757182, 'filtered_reward': 0.09301589884912548, 'rollout_width': 23, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 110 score=0.341, mean_reward=0.271, best_reward=0.505, params={'1-top_p': 0.0037865110094160467, 'temperature': 0.7841149743982059, 'policy_class': 'UCB', 'c': 0.3876872731518557, 'best_rate': 0.7406438374357064, 'filtered_reward': 0.1519263005541624, 'rollout_width': 22, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 111 score=0.379, mean_reward=0.298, best_reward=0.567, params={'1-top_p': 0.003606982815271662, 'temperature': 0.7815620017529368, 'policy_class': 'UCB', 'c': 0.35240006006982294, 'best_rate': 0.5916538751347045, 'filtered_reward': 0.04445900641856876, 'rollout_width': 38, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 112 score=0.354, mean_reward=0.287, best_reward=0.508, params={'1-top_p': 0.0014356151131246359, 'temperature': 0.7813642466145103, 'policy_class': 'UCB', 'c': 0.2866616336598373, 'best_rate': 0.547682090567422, 'filtered_reward': 0.0799469198806119, 'rollout_width': 22, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 113 score=0.417, mean_reward=0.354, best_reward=0.565, params={'1-top_p': 0.0027940112268314394, 'temperature': 0.7042582290684625, 'policy_class': 'UCB', 'c': 0.38244344962176113, 'best_rate': 0.4725845702052091, 'filtered_reward': 0.14811289432984714, 'rollout_width': 24, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 114 score=0.431, mean_reward=0.364, best_reward=0.588, params={'1-top_p': 0.002300949533907523, 'temperature': 0.7972448594532742, 'policy_class': 'UCB', 'c': 0.4068105177461451, 'best_rate': 0.5110470182586627, 'filtered_reward': 0.10588989566168398, 'rollout_width': 25, 'n_rollouts': 4, 'n_tries': 2}\n",
            "Trial 115 score=0.406, mean_reward=0.350, best_reward=0.534, params={'1-top_p': 0.003165827009584744, 'temperature': 0.8117164282479846, 'policy_class': 'UCB', 'c': 0.22810706501562633, 'best_rate': 0.6779204427518857, 'filtered_reward': 0.13782694382680646, 'rollout_width': 26, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 116 score=0.437, mean_reward=0.373, best_reward=0.586, params={'1-top_p': 0.003853967249058907, 'temperature': 0.7501371187469275, 'policy_class': 'UCB', 'c': 0.4197107261321589, 'best_rate': 0.5292551814150994, 'filtered_reward': 0.07963683615981267, 'rollout_width': 21, 'n_rollouts': 4, 'n_tries': 2}\n",
            "Trial 117 score=0.401, mean_reward=0.344, best_reward=0.533, params={'1-top_p': 0.003678605919088833, 'temperature': 0.7931382572464841, 'policy_class': 'UCB', 'c': 0.24270307677367897, 'best_rate': 0.5964424647504171, 'filtered_reward': -0.3772008091262615, 'rollout_width': 18, 'n_rollouts': 3, 'n_tries': 2}\n",
            "Trial 118 score=0.404, mean_reward=0.322, best_reward=0.597, params={'1-top_p': 0.004197635373664896, 'temperature': 0.8589743615594977, 'policy_class': 'UCB', 'c': 0.349454211372497, 'best_rate': 0.4798541945537688, 'filtered_reward': 0.04142332259339032, 'rollout_width': 19, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 119 score=0.414, mean_reward=0.354, best_reward=0.554, params={'1-top_p': 0.0033707784719621205, 'temperature': 0.8385439804569235, 'policy_class': 'UCB', 'c': 0.2889999095649514, 'best_rate': 0.7256284124854468, 'filtered_reward': 0.15536201496118046, 'rollout_width': 16, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 120 score=0.359, mean_reward=0.294, best_reward=0.512, params={'1-top_p': 0.002763200735262286, 'temperature': 0.7581183422469505, 'policy_class': 'UCB', 'c': 0.3088674199805723, 'best_rate': 0.07314870546399396, 'filtered_reward': 0.19801518785846525, 'rollout_width': 21, 'n_rollouts': 7, 'n_tries': 2}\n",
            "Trial 121 score=0.362, mean_reward=0.281, best_reward=0.551, params={'1-top_p': 0.003116695618694467, 'temperature': 0.8230592977751482, 'policy_class': 'UCB', 'c': 0.4547233961598185, 'best_rate': 0.67835319923623, 'filtered_reward': 0.09842934956572101, 'rollout_width': 14, 'n_rollouts': 4, 'n_tries': 2}\n",
            "Trial 122 score=0.355, mean_reward=0.286, best_reward=0.517, params={'1-top_p': 0.0035433996220711815, 'temperature': 0.850133008241648, 'policy_class': 'UCB', 'c': 0.4149238909771584, 'best_rate': 0.6568124718563604, 'filtered_reward': 0.0657527065013872, 'rollout_width': 29, 'n_rollouts': 1, 'n_tries': 2}\n",
            "Trial 123 score=0.348, mean_reward=0.263, best_reward=0.547, params={'1-top_p': 0.004373596321956479, 'temperature': 0.8961618381968358, 'policy_class': 'UCB', 'c': 0.4800579876872393, 'best_rate': 0.15511444631248406, 'filtered_reward': 0.12680320758027566, 'rollout_width': 18, 'n_rollouts': 3, 'n_tries': 2}\n",
            "Trial 124 score=0.412, mean_reward=0.346, best_reward=0.565, params={'1-top_p': 0.0034866091653915983, 'temperature': 0.8468482348172991, 'policy_class': 'UCB', 'c': 0.2759495461630234, 'best_rate': 0.6181335424531603, 'filtered_reward': -0.2757704108715732, 'rollout_width': 15, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 125 score=0.466, mean_reward=0.397, best_reward=0.626, params={'1-top_p': 0.0037966919609139526, 'temperature': 0.8178476620544468, 'policy_class': 'UCB', 'c': 0.3211634930872266, 'best_rate': 0.6951763699594237, 'filtered_reward': 0.1221179769020247, 'rollout_width': 15, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 126 score=0.445, mean_reward=0.376, best_reward=0.604, params={'1-top_p': 0.004892105154259725, 'temperature': 0.80321639383027, 'policy_class': 'UCB', 'c': 0.3275375989245561, 'best_rate': 0.759305347931317, 'filtered_reward': 0.16979758129575084, 'rollout_width': 16, 'n_rollouts': 6, 'n_tries': 2}\n",
            "Trial 127 score=0.424, mean_reward=0.351, best_reward=0.594, params={'1-top_p': 0.0037230113997137313, 'temperature': 0.8337575736431896, 'policy_class': 'UCB', 'c': 0.3621032588365905, 'best_rate': 0.5574092002502505, 'filtered_reward': 0.11834780196292483, 'rollout_width': 20, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 128 score=0.382, mean_reward=0.320, best_reward=0.529, params={'1-top_p': 0.0032264052828713434, 'temperature': 0.8229227092660294, 'policy_class': 'UCB', 'c': 0.30582350031428923, 'best_rate': 0.4933222112227702, 'filtered_reward': -0.09586825406493979, 'rollout_width': 15, 'n_rollouts': 4, 'n_tries': 2}\n",
            "Trial 129 score=0.442, mean_reward=0.381, best_reward=0.586, params={'1-top_p': 0.00431509429985028, 'temperature': 0.7894709518395229, 'policy_class': 'UCB', 'c': 0.24607571358415933, 'best_rate': 0.3780660630822349, 'filtered_reward': 0.08079122921938246, 'rollout_width': 14, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 130 score=0.475, mean_reward=0.410, best_reward=0.626, params={'1-top_p': 0.003894250709222688, 'temperature': 0.8089908319501901, 'policy_class': 'UCB', 'c': 0.34242582691609663, 'best_rate': 0.6840576929173767, 'filtered_reward': -0.018081066313688526, 'rollout_width': 12, 'n_rollouts': 6, 'n_tries': 2}\n",
            "Trial 131 score=0.439, mean_reward=0.376, best_reward=0.586, params={'1-top_p': 0.0038708257394835664, 'temperature': 0.768082456842294, 'policy_class': 'UCB', 'c': 0.3863928484549039, 'best_rate': 0.6821783842171807, 'filtered_reward': -0.001051733163003693, 'rollout_width': 12, 'n_rollouts': 6, 'n_tries': 2}\n",
            "Trial 132 score=0.426, mean_reward=0.355, best_reward=0.592, params={'1-top_p': 0.004884861003091615, 'temperature': 0.8126152153240149, 'policy_class': 'UCB', 'c': 0.44607467477889884, 'best_rate': 0.7286852491155443, 'filtered_reward': 0.048160134753753615, 'rollout_width': 16, 'n_rollouts': 6, 'n_tries': 2}\n",
            "Trial 133 score=0.359, mean_reward=0.288, best_reward=0.526, params={'1-top_p': 0.0040214984299944455, 'temperature': 0.8199934988227762, 'policy_class': 'UCB', 'c': 0.35089615360937315, 'best_rate': 0.7883219670328246, 'filtered_reward': 0.14221717042066304, 'rollout_width': 18, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 134 score=0.443, mean_reward=0.360, best_reward=0.635, params={'1-top_p': 0.0028697160625617605, 'temperature': 0.8605402258276482, 'policy_class': 'UCB', 'c': 0.3226527920753296, 'best_rate': 0.6328524756181041, 'filtered_reward': -0.07267557750160625, 'rollout_width': 13, 'n_rollouts': 5, 'n_tries': 2}\n",
            "Trial 135 score=0.386, mean_reward=0.327, best_reward=0.525, params={'1-top_p': 0.003308290279563646, 'temperature': 0.8062502761013325, 'policy_class': 'UCB', 'c': 0.29546328632967056, 'best_rate': 0.6596277416700458, 'filtered_reward': -0.21332178138109076, 'rollout_width': 19, 'n_rollouts': 6, 'n_tries': 2}\n"
          ]
        }
      ],
      "source": [
        "# continue search\n",
        "study = optuna.study.load_study(study_name=\"d_score_25000\", storage=\"sqlite:///generation_result/optuna_d_score_25000.db\")\n",
        "study.optimize(objective, n_trials=150, callbacks=[log_callback])\n",
        "print_best_trials(study)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
