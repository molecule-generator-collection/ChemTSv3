{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language\n",
        "from node import MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "optuna.logging.disable_default_handler()\n",
        "\n",
        "yaml_path = \"config/optuna_generation.yaml\"\n",
        "\n",
        "with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "    conf = yaml.safe_load(f)\n",
        "transition_args = conf.get(\"transition_args\", {})\n",
        "model_dir = os.path.join(repo_root, transition_args.pop(\"model_dir\"))\n",
        "lang_path = conf.get(\"lang_path\")\n",
        "if lang_path is None:\n",
        "    lang_name = os.path.basename(os.path.normpath(model_dir)) + \".lang\"\n",
        "    lang_path = add_sep(model_dir) + lang_name\n",
        "lang = Language.load(lang_path)\n",
        "policy_args = conf.get(\"policy_args\", {})\n",
        "reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "filter_settings = conf.get(\"filters\", [])\n",
        "filters = []\n",
        "for s in filter_settings:\n",
        "    filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "    filters.append(filter_class(**s))\n",
        "generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "def objective(trial):\n",
        "    transition_args[\"top_p\"] = 1 - trial.suggest_loguniform(\"1-top_p\", 0.002, 0.02)\n",
        "    transition_args[\"temperature\"] = trial.suggest_uniform(\"temperature\", 0.8, 1.2)\n",
        "    policy_class = trial.suggest_categorical(\"policy_class\", [\"UCB\", \"PUCT\"])\n",
        "    policy_args[\"c\"] = trial.suggest_loguniform(\"c\", 0.01, 2)\n",
        "    policy_args[\"best_rate\"] = trial.suggest_uniform(\"best_rate\", 0, 1)\n",
        "    generator_args[\"filtered_reward\"] = trial.suggest_uniform(\"filtered_reward\", -2, 0.2)\n",
        "    generator_args[\"rollout_width\"] = trial.suggest_int(\"rollout_width\", 1, 10)\n",
        "    generator_args[\"allow_rollout_overlaps\"] = trial.suggest_categorical(\"allow_rollout_overlaps\", [True, False])\n",
        "    generator_args[\"n_rollouts\"] = trial.suggest_int(\"n_rollouts\", 1, 10)\n",
        "    generator_args[\"n_tries\"] = trial.suggest_int(\"n_tries\", 1, 10)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    console_level = logging.ERROR\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, console_level=console_level, file_level=file_level)\n",
        "    logger.info(\"params:\" + str(trial.params))\n",
        "\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(model_dir=model_dir, lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "    \n",
        "    policy_class = class_from_package(\"policy\", policy_class)\n",
        "    policy = policy_class(**policy_args)\n",
        "    generator_args[\"policy\"] = policy\n",
        "        \n",
        "    root = MolSentenceNode.bos_node(lang, device=conf.get(\"device\")) # TODO: change after root node generalization\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    best_reward_rate = conf.get(\"best_reward_rate\")\n",
        "    mean_reward = generator.mean_reward(window=conf.get(\"mean_reward_window\"))\n",
        "    trial.set_user_attr(\"mean_reward\", mean_reward)\n",
        "    trial.set_user_attr(\"best_reward\", generator.best_reward)\n",
        "    return (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "\n",
        "def log_callback(study: optuna.Study, trial: optuna.Trial):\n",
        "    val = trial.value\n",
        "    print_trial(trial)\n",
        "    \n",
        "def print_trial(trial: optuna.Trial):\n",
        "    print(f\"Trial {trial.number} score={trial.value:.3f}, mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}, params={trial.params}\")\n",
        "    \n",
        "def print_best_trials(study: optuna.Study):\n",
        "    print(\"Optuna trials completed.\")\n",
        "    print(\"------ Best trials -----\")\n",
        "    best_trials = sorted([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE], key=lambda t: t.value, reverse=True)[:5]\n",
        "    for t in best_trials:\n",
        "        print_trial(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0 score=0.259, mean_reward=0.177, best_reward=0.450, params={'1-top_p': 0.01311618576535542, 'temperature': 0.909535226412763, 'policy_class': 'PUCT', 'c': 0.010156568262119215, 'best_rate': 0.9106261790495621, 'filtered_reward': -0.5800526439568316, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 4, 'n_tries': 10}\n",
            "Trial 1 score=0.297, mean_reward=0.227, best_reward=0.459, params={'1-top_p': 0.0052619152221884255, 'temperature': 0.9602059116067898, 'policy_class': 'UCB', 'c': 0.03025987391770358, 'best_rate': 0.89326870230366, 'filtered_reward': -0.011185826239096919, 'rollout_width': 7, 'allow_rollout_overlaps': True, 'n_rollouts': 1, 'n_tries': 6}\n",
            "Trial 2 score=0.220, mean_reward=0.136, best_reward=0.417, params={'1-top_p': 0.01512668816478695, 'temperature': 1.0549615879883538, 'policy_class': 'PUCT', 'c': 0.5450707599166557, 'best_rate': 0.296298006934008, 'filtered_reward': -1.6193171859292772, 'rollout_width': 1, 'allow_rollout_overlaps': True, 'n_rollouts': 7, 'n_tries': 6}\n",
            "Trial 3 score=0.277, mean_reward=0.201, best_reward=0.452, params={'1-top_p': 0.0090379512883844, 'temperature': 0.9899649023032948, 'policy_class': 'UCB', 'c': 0.01700484682943419, 'best_rate': 0.5235821162799542, 'filtered_reward': -0.9721096619511214, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 7, 'n_tries': 1}\n",
            "Trial 4 score=0.218, mean_reward=0.140, best_reward=0.401, params={'1-top_p': 0.0038299351485567203, 'temperature': 1.0878273521659152, 'policy_class': 'PUCT', 'c': 0.6030922817803638, 'best_rate': 0.7696082945594807, 'filtered_reward': -0.5088325327478462, 'rollout_width': 7, 'allow_rollout_overlaps': True, 'n_rollouts': 2, 'n_tries': 7}\n",
            "Trial 5 score=0.203, mean_reward=0.105, best_reward=0.430, params={'1-top_p': 0.006921209375395074, 'temperature': 0.9596234609214995, 'policy_class': 'UCB', 'c': 0.3847620717743962, 'best_rate': 0.9264730306613622, 'filtered_reward': -1.0325375899331681, 'rollout_width': 10, 'allow_rollout_overlaps': True, 'n_rollouts': 8, 'n_tries': 7}\n",
            "Trial 6 score=0.305, mean_reward=0.250, best_reward=0.435, params={'1-top_p': 0.0030003764380921194, 'temperature': 1.0553252733334593, 'policy_class': 'UCB', 'c': 0.011646020828873567, 'best_rate': 0.9775108169509699, 'filtered_reward': 0.1084896337707355, 'rollout_width': 6, 'allow_rollout_overlaps': True, 'n_rollouts': 2, 'n_tries': 6}\n",
            "Trial 7 score=0.289, mean_reward=0.226, best_reward=0.437, params={'1-top_p': 0.01120192692349989, 'temperature': 0.915039667640368, 'policy_class': 'UCB', 'c': 0.13012277398782965, 'best_rate': 0.4387759617924065, 'filtered_reward': -0.9403162528987405, 'rollout_width': 6, 'allow_rollout_overlaps': False, 'n_rollouts': 1, 'n_tries': 10}\n",
            "Trial 8 score=0.215, mean_reward=0.123, best_reward=0.429, params={'1-top_p': 0.0030682016960071113, 'temperature': 0.9026270452108555, 'policy_class': 'UCB', 'c': 0.7562893742600969, 'best_rate': 0.22437019809235614, 'filtered_reward': -0.26872230481094417, 'rollout_width': 3, 'allow_rollout_overlaps': False, 'n_rollouts': 4, 'n_tries': 8}\n",
            "Trial 9 score=0.230, mean_reward=0.140, best_reward=0.439, params={'1-top_p': 0.01708025699603869, 'temperature': 1.1021899733161917, 'policy_class': 'UCB', 'c': 0.23622755433768064, 'best_rate': 0.763868906611918, 'filtered_reward': -0.1513668733550726, 'rollout_width': 6, 'allow_rollout_overlaps': True, 'n_rollouts': 10, 'n_tries': 6}\n",
            "Optuna trials completed.\n",
            "------ Best trials -----\n",
            "Trial 6 score=0.305, mean_reward=0.250, best_reward=0.435, params={'1-top_p': 0.0030003764380921194, 'temperature': 1.0553252733334593, 'policy_class': 'UCB', 'c': 0.011646020828873567, 'best_rate': 0.9775108169509699, 'filtered_reward': 0.1084896337707355, 'rollout_width': 6, 'allow_rollout_overlaps': True, 'n_rollouts': 2, 'n_tries': 6}\n",
            "Trial 1 score=0.297, mean_reward=0.227, best_reward=0.459, params={'1-top_p': 0.0052619152221884255, 'temperature': 0.9602059116067898, 'policy_class': 'UCB', 'c': 0.03025987391770358, 'best_rate': 0.89326870230366, 'filtered_reward': -0.011185826239096919, 'rollout_width': 7, 'allow_rollout_overlaps': True, 'n_rollouts': 1, 'n_tries': 6}\n",
            "Trial 7 score=0.289, mean_reward=0.226, best_reward=0.437, params={'1-top_p': 0.01120192692349989, 'temperature': 0.915039667640368, 'policy_class': 'UCB', 'c': 0.13012277398782965, 'best_rate': 0.4387759617924065, 'filtered_reward': -0.9403162528987405, 'rollout_width': 6, 'allow_rollout_overlaps': False, 'n_rollouts': 1, 'n_tries': 10}\n",
            "Trial 3 score=0.277, mean_reward=0.201, best_reward=0.452, params={'1-top_p': 0.0090379512883844, 'temperature': 0.9899649023032948, 'policy_class': 'UCB', 'c': 0.01700484682943419, 'best_rate': 0.5235821162799542, 'filtered_reward': -0.9721096619511214, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 7, 'n_tries': 1}\n",
            "Trial 0 score=0.259, mean_reward=0.177, best_reward=0.450, params={'1-top_p': 0.01311618576535542, 'temperature': 0.909535226412763, 'policy_class': 'PUCT', 'c': 0.010156568262119215, 'best_rate': 0.9106261790495621, 'filtered_reward': -0.5800526439568316, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 4, 'n_tries': 10}\n"
          ]
        }
      ],
      "source": [
        "name = conf.get(\"study_name\")\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=name, storage=\"sqlite:///generation_result/optuna_\" + name + \".db\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=conf.get(\"n_trials\"), callbacks=[log_callback])\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# continue\n",
        "optuna.study.load_study(study_name=\"d_score\", storage=\"sqlite:///generation_result/optuna_d_score.db\")\n",
        "study.optimize(objective, n_trials=3, callbacks=[log_callback])\n",
        "print_best_trials(study)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
