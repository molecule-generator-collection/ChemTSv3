{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for class boost::shared_ptr<class RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
            "c:\\Users\\fsfsf\\anaconda3\\envs\\v3-forge\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language\n",
        "from node import MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "optuna.logging.disable_default_handler()\n",
        "\n",
        "yaml_path = \"config/optuna_generation.yaml\"\n",
        "with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "    conf = yaml.safe_load(f)\n",
        "transition_args = conf.get(\"transition_args\", {})\n",
        "model_dir = os.path.join(repo_root, transition_args.pop(\"model_dir\"))\n",
        "lang_path = conf.get(\"lang_path\")\n",
        "if lang_path is None:\n",
        "    lang_name = os.path.basename(os.path.normpath(model_dir)) + \".lang\"\n",
        "    lang_path = add_sep(model_dir) + lang_name\n",
        "lang = Language.load(lang_path)\n",
        "reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "filter_settings = conf.get(\"filters\", [])\n",
        "filters = []\n",
        "for s in filter_settings:\n",
        "    filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "    filters.append(filter_class(**s))\n",
        "generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "def objective(trial):\n",
        "    policy_class = trial.suggest_categorical(\"policy_class\", [\"UCB\", \"PUCT\"])\n",
        "    c = trial.suggest_loguniform(\"c\", 0.01, 2)\n",
        "    best_rate = trial.suggest_uniform(\"best_rate\", 0, 1)\n",
        "    rollout_width = trial.suggest_int(\"rollout_width\", 1, 10)\n",
        "    allow_rollout_overlaps = trial.suggest_categorical(\"allow_rollout_overlaps\", [True, False])\n",
        "    n_rollouts = trial.suggest_int(\"n_rollouts\", 1, 10)\n",
        "    n_tries = trial.suggest_int(\"n_tries\", 1, 10)\n",
        "    bottom_p = trial.suggest_loguniform(\"1-top_p\", 0.002, 0.02)\n",
        "    top_p = 1 - bottom_p\n",
        "    temperature = trial.suggest_uniform(\"temperature\", 0.8, 1.2)\n",
        "    filtered_reward = trial.suggest_uniform(\"filtered_reward\", -2, 0.2)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    console_level = logging.ERROR\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, console_level=console_level, file_level=file_level)\n",
        "    logger.info(\"params:\" + str(trial.params))\n",
        "\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition_args[\"top_p\"] = top_p\n",
        "    transition_args[\"temperature\"] = temperature\n",
        "    transition = transition_class(model_dir=model_dir, lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "    \n",
        "    policy_class = class_from_package(\"policy\", policy_class)\n",
        "    policy = policy_class(c=c, best_rate=best_rate)\n",
        "    generator_args[\"policy\"] = policy\n",
        "        \n",
        "    root = MolSentenceNode.bos_node(lang, device=conf.get(\"device\")) # TODO: change after root node generalization\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator_args[\"filtered_reward\"] = filtered_reward\n",
        "    generator_args[\"rollout_width\"] = rollout_width\n",
        "    generator_args[\"allow_rollout_overlaps\"] = allow_rollout_overlaps\n",
        "    generator_args[\"n_rollouts\"] = n_rollouts\n",
        "    generator_args[\"n_tries\"] = n_tries\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    best_reward_rate = conf.get(\"best_reward_rate\")\n",
        "    mean_reward = generator.mean_reward(window=conf.get(\"mean_reward_window\"))\n",
        "    trial.set_user_attr(\"mean_reward\", mean_reward)\n",
        "    trial.set_user_attr(\"best_reward\", generator.best_reward)\n",
        "    return (1 - best_reward_rate) * mean_reward + best_reward_rate * generator.best_reward\n",
        "\n",
        "def log_callback(study: optuna.Study, trial: optuna.Trial):\n",
        "    val = trial.value\n",
        "    print_trial(trial)\n",
        "    \n",
        "def print_trial(trial: optuna.Trial):\n",
        "    print(f\"Trial {trial.number} score={trial.value:.3f}, mean_reward={trial.user_attrs['mean_reward']:.3f}, best_reward={trial.user_attrs['best_reward']:.3f}, params={trial.params}\")\n",
        "    \n",
        "def print_best_trials(study: optuna.Study):\n",
        "    print(\"Optuna trials completed.\")\n",
        "    print(\"------ Best trials -----\")\n",
        "    best_trials = sorted([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE], key=lambda t: t.value, reverse=True)[:5]\n",
        "    for t in best_trials:\n",
        "        print_trial(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 0 score=0.177, mean_reward=0.072, best_reward=0.421, params={'policy_class': 'UCB', 'c': 1.1805346343994227, 'best_rate': 0.3216831378235876, 'rollout_width': 3, 'allow_rollout_overlaps': True, 'n_rollouts': 2, 'n_tries': 6, '1-top_p': 0.008627714274871436, 'temperature': 1.1386610098478531, 'filtered_reward': -0.03002868874706288}\n",
            "Trial 1 score=0.204, mean_reward=0.103, best_reward=0.441, params={'policy_class': 'UCB', 'c': 0.06586752586079238, 'best_rate': 0.6763655162087864, 'rollout_width': 8, 'allow_rollout_overlaps': False, 'n_rollouts': 10, 'n_tries': 1, '1-top_p': 0.008688041862370485, 'temperature': 0.9987216225241677, 'filtered_reward': -1.777585203280518}\n",
            "Trial 2 score=0.235, mean_reward=0.169, best_reward=0.387, params={'policy_class': 'PUCT', 'c': 0.012240554470821606, 'best_rate': 0.6134962590747709, 'rollout_width': 10, 'allow_rollout_overlaps': True, 'n_rollouts': 6, 'n_tries': 1, '1-top_p': 0.01997965011739437, 'temperature': 1.032407605689511, 'filtered_reward': 0.18509944962414338}\n",
            "Trial 3 score=0.341, mean_reward=0.313, best_reward=0.408, params={'policy_class': 'UCB', 'c': 0.015256244141237654, 'best_rate': 0.4294509717512264, 'rollout_width': 4, 'allow_rollout_overlaps': False, 'n_rollouts': 7, 'n_tries': 4, '1-top_p': 0.01230947378675027, 'temperature': 1.072570376588664, 'filtered_reward': 0.09023851916716108}\n",
            "Trial 4 score=0.219, mean_reward=0.119, best_reward=0.453, params={'policy_class': 'UCB', 'c': 0.06669403004215937, 'best_rate': 0.42342974438718506, 'rollout_width': 1, 'allow_rollout_overlaps': True, 'n_rollouts': 8, 'n_tries': 4, '1-top_p': 0.017742323507942293, 'temperature': 1.1339362752966105, 'filtered_reward': -0.9164349232879319}\n",
            "Trial 5 score=0.255, mean_reward=0.190, best_reward=0.407, params={'policy_class': 'PUCT', 'c': 0.1290850285858945, 'best_rate': 0.7269297131536446, 'rollout_width': 7, 'allow_rollout_overlaps': True, 'n_rollouts': 10, 'n_tries': 2, '1-top_p': 0.0066402559701001845, 'temperature': 1.1198565257481696, 'filtered_reward': -1.3017649672494123}\n",
            "Trial 6 score=0.286, mean_reward=0.209, best_reward=0.467, params={'policy_class': 'UCB', 'c': 0.07811588049751658, 'best_rate': 0.6334112762133695, 'rollout_width': 1, 'allow_rollout_overlaps': False, 'n_rollouts': 4, 'n_tries': 3, '1-top_p': 0.015455354751958464, 'temperature': 0.9356727676968045, 'filtered_reward': -0.6749332801577179}\n",
            "Trial 7 score=0.172, mean_reward=0.060, best_reward=0.432, params={'policy_class': 'PUCT', 'c': 0.6343535302359765, 'best_rate': 0.26012680132297605, 'rollout_width': 1, 'allow_rollout_overlaps': True, 'n_rollouts': 9, 'n_tries': 8, '1-top_p': 0.00968395284361908, 'temperature': 0.8658406218182074, 'filtered_reward': -0.3002841164844945}\n",
            "Trial 8 score=0.283, mean_reward=0.210, best_reward=0.453, params={'policy_class': 'UCB', 'c': 0.011080640006095896, 'best_rate': 0.26690052534238706, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 6, 'n_tries': 3, '1-top_p': 0.002006667481780564, 'temperature': 0.8751981258168428, 'filtered_reward': -0.9774453252248398}\n",
            "Trial 9 score=0.270, mean_reward=0.210, best_reward=0.409, params={'policy_class': 'PUCT', 'c': 0.28954937031805694, 'best_rate': 0.5135931710989153, 'rollout_width': 7, 'allow_rollout_overlaps': False, 'n_rollouts': 3, 'n_tries': 4, '1-top_p': 0.01728711334094922, 'temperature': 1.0504180820253874, 'filtered_reward': -0.38196504818854193}\n",
            "Optuna trials completed.\n",
            "------ Best trials -----\n",
            "Trial 3 score=0.341, mean_reward=0.313, best_reward=0.408, params={'policy_class': 'UCB', 'c': 0.015256244141237654, 'best_rate': 0.4294509717512264, 'rollout_width': 4, 'allow_rollout_overlaps': False, 'n_rollouts': 7, 'n_tries': 4, '1-top_p': 0.01230947378675027, 'temperature': 1.072570376588664, 'filtered_reward': 0.09023851916716108}\n",
            "Trial 6 score=0.286, mean_reward=0.209, best_reward=0.467, params={'policy_class': 'UCB', 'c': 0.07811588049751658, 'best_rate': 0.6334112762133695, 'rollout_width': 1, 'allow_rollout_overlaps': False, 'n_rollouts': 4, 'n_tries': 3, '1-top_p': 0.015455354751958464, 'temperature': 0.9356727676968045, 'filtered_reward': -0.6749332801577179}\n",
            "Trial 8 score=0.283, mean_reward=0.210, best_reward=0.453, params={'policy_class': 'UCB', 'c': 0.011080640006095896, 'best_rate': 0.26690052534238706, 'rollout_width': 8, 'allow_rollout_overlaps': True, 'n_rollouts': 6, 'n_tries': 3, '1-top_p': 0.002006667481780564, 'temperature': 0.8751981258168428, 'filtered_reward': -0.9774453252248398}\n",
            "Trial 9 score=0.270, mean_reward=0.210, best_reward=0.409, params={'policy_class': 'PUCT', 'c': 0.28954937031805694, 'best_rate': 0.5135931710989153, 'rollout_width': 7, 'allow_rollout_overlaps': False, 'n_rollouts': 3, 'n_tries': 4, '1-top_p': 0.01728711334094922, 'temperature': 1.0504180820253874, 'filtered_reward': -0.38196504818854193}\n",
            "Trial 5 score=0.255, mean_reward=0.190, best_reward=0.407, params={'policy_class': 'PUCT', 'c': 0.1290850285858945, 'best_rate': 0.7269297131536446, 'rollout_width': 7, 'allow_rollout_overlaps': True, 'n_rollouts': 10, 'n_tries': 2, '1-top_p': 0.0066402559701001845, 'temperature': 1.1198565257481696, 'filtered_reward': -1.3017649672494123}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", study_name=conf.get(\"study_name\"), storage=\"sqlite:///generation_result/optuna_d_score.db\", sampler=optuna.samplers.TPESampler())\n",
        "study.optimize(objective, n_trials=conf.get(\"n_trials\"), callbacks=[log_callback])\n",
        "print_best_trials(study)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# continue\n",
        "optuna.study.load_study(study_name=\"d_score\", storage=\"sqlite:///generation_result/optuna_d_score.db\")\n",
        "study.optimize(objective, n_trials=3, callbacks=[log_callback])\n",
        "print_best_trials(study)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
