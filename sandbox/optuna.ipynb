{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/v3-forge/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "<frozen importlib._bootstrap>:241: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterHierarchyMatcher> already registered; second conversion method ignored.\n",
            "[I 2025-06-20 19:32:33,535] A new study created in memory with name: no-name-3c1f4ed9-3771-41c2-9c4e-f5ee7c678b0e\n",
            "UCB c=0.026857818687410166 best_rate=0.7098564487488787 top_p=0.9978874434775374, temperature=1.0955261592917813, n_rollouts=3 n_tries=5 filtered_reward=-1.3290775473685104\n",
            "Is CUDA available: False\n",
            "Starting generation...\n",
            "<best reward updated> order: 1, time: 0.00, reward: 0.3419, node: O[C@@H]1COC2(CCOCC2)S/C1=N\\c1ccccc1\n",
            "<best reward updated> order: 3, time: 0.00, reward: 0.3612, node: OC[C@H](O)CSc1ccccc1Cl\n",
            "<best reward updated> order: 31, time: 1.44, reward: 0.3678, node: ClCO[C@@H]1CCOC2(CCOCC2)C1\n",
            "<best reward updated> order: 41, time: 1.87, reward: 0.3832, node: CNC(=O)[C@H]1Cc2ccccc2CN1C(=O)C1CC=CC1\n",
            "<best reward updated> order: 95, time: 3.54, reward: 0.3981, node: C[C@H](C(=O)[O-])c1ccc(Cl)cc1Cl\n",
            "generated: 100, time: 3.96, average over 100: 0.1520\n",
            "<best reward updated> order: 138, time: 4.91, reward: 0.4089, node: C/S(=O)(=O)CN1C(=O)CCc2ccc(C(=O)[O-])cc21\n",
            "generated: 200, time: 6.97, average over 100: 0.1189\n",
            "<best reward updated> order: 300, time: 10.37, reward: 0.4534, node: C/C(N)S[C@H]1C(=O)N=C(C)Nc2nnnn21\n",
            "<best reward updated> order: 305, time: 10.42, reward: 0.4754, node: C/C(N)[C@@H]1C(C(=O)[O-])=CNC(=O)C[C@H]1c1ccncc1\n",
            "generated: 400, time: 13.00, average over 100: 0.1562\n",
            "generated: 500, time: 16.55, average over 100: 0.1718\n",
            "generated: 600, time: 19.74, average over 100: 0.1490\n",
            "generated: 700, time: 22.85, average over 100: 0.2214\n",
            "generated: 800, time: 26.28, average over 100: 0.2436\n",
            "generated: 900, time: 31.43, average over 100: 0.2293\n",
            "generated: 1000, time: 37.38, average over 100: 0.2291\n",
            "generated: 1100, time: 45.07, average over 100: 0.2279\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "import optuna\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language\n",
        "from node import MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "yaml_path = \"config/mcts_d_score.yaml\"\n",
        "\n",
        "def objective(trial):\n",
        "    policy_class = trial.suggest_categorical(\"policy_class\", [\"UCB\", \"PUCT\"])\n",
        "    c = trial.suggest_loguniform(\"c\", 0.01, 2)\n",
        "    best_rate = trial.suggest_uniform(\"best_rate\", 0, 1)\n",
        "    n_rollouts = trial.suggest_int(\"n_rollouts\", 1, 5)\n",
        "    n_tries = trial.suggest_int(\"n_tries\", 1, 5)\n",
        "    bottom_p = trial.suggest_loguniform(\"1-top_p\", 0.0005, 0.05)\n",
        "    top_p = 1 - bottom_p\n",
        "    temperature = trial.suggest_uniform(\"temperature\", 0.8, 1.2)\n",
        "    \n",
        "    filtered_reward = trial.suggest_uniform(\"filtered_reward\", -2, 0.2)\n",
        "    \n",
        "    with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "        conf = yaml.safe_load(f)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, file_level=file_level)\n",
        "    logger.info(f\"{policy_class} c={c} best_rate={best_rate} top_p={top_p}, temperature={temperature}, n_rollouts={n_rollouts} n_tries={n_tries} filtered_reward={filtered_reward}\")\n",
        "    generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "    transition_args = conf.get(\"transition_args\", {})\n",
        "    transition_args[\"top_p\"] = top_p\n",
        "    transition_args[\"temperature\"] = temperature\n",
        "    if \"model_dir\" in transition_args:\n",
        "        transition_args[\"model_dir\"] = os.path.join(repo_root, transition_args[\"model_dir\"])\n",
        "    lang_path = conf.get(\"lang_path\")\n",
        "    if lang_path is None:\n",
        "        lang_name = os.path.basename(os.path.normpath(transition_args[\"model_dir\"])) + \".lang\"\n",
        "        lang_path = add_sep(transition_args[\"model_dir\"]) + lang_name\n",
        "    lang = Language.load(lang_path)\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "\n",
        "    reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "    reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "    \n",
        "    policy_class = class_from_package(\"policy\", policy_class)\n",
        "    policy = policy_class(c=c, best_rate=best_rate)\n",
        "    generator_args[\"policy\"] = policy\n",
        "\n",
        "    filter_settings = conf.get(\"filters\", [])\n",
        "    filters = []\n",
        "    for s in filter_settings:\n",
        "        filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "        filters.append(filter_class(**s))\n",
        "        \n",
        "    root = MolSentenceNode.bos_node(lang, device=conf.get(\"device\")) # TODO: change after root node generalization\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator_args[\"filtered_reward\"] = filtered_reward\n",
        "    generator_args[\"n_rollouts\"] = n_rollouts\n",
        "    generator_args[\"n_tries\"] = n_tries\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    return 0.95 * generator.mean_reward(window=2000) + 0.05 * generator.best_reward\n",
        "    \n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print(f'Best value: {study.best_value}')\n",
        "print(f'Best param: {study.best_params}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
