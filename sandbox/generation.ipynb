{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language, MolLanguage\n",
        "from node import SurrogateNode, SentenceNode, MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "\n",
        "RDLogger.DisableLog('rdApp.*') # use debug: true to log invalid mols\n",
        "\n",
        "def read_yaml(yaml_path: str) -> tuple[Generator, dict[str, Any]]:\n",
        "    with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "        conf = yaml.safe_load(f)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, file_level=file_level)\n",
        "    generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "    transition_args = conf.get(\"transition_args\", {})\n",
        "    if \"model_dir\" in transition_args:\n",
        "        transition_args[\"model_dir\"] = os.path.join(repo_root, transition_args[\"model_dir\"])\n",
        "    lang_path = conf.get(\"lang_path\")\n",
        "    if lang_path is None:\n",
        "        lang_name = os.path.basename(os.path.normpath(transition_args[\"model_dir\"])) + \".lang\"\n",
        "        lang_path = add_sep(transition_args[\"model_dir\"]) + lang_name\n",
        "    lang = Language.load(lang_path)\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "\n",
        "    reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "    reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "    \n",
        "    if \"policy_class\" in conf:\n",
        "        policy_class = class_from_package(\"policy\", conf.get(\"policy_class\"))\n",
        "        policy = policy_class(**conf.get(\"policy_args\", {}))\n",
        "        generator_args[\"policy\"] = policy\n",
        "\n",
        "    filter_settings = conf.get(\"filters\", [])\n",
        "    filters = []\n",
        "    for s in filter_settings:\n",
        "        filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "        filters.append(filter_class(**s))\n",
        "\n",
        "    if \"node_class\" in conf:\n",
        "        node_class = class_from_package(\"node\", conf.get(\"node_class\"))\n",
        "    elif issubclass(lang.__class__, MolLanguage):\n",
        "        node_class = MolSentenceNode\n",
        "    elif issubclass(lang.__class__, Language):\n",
        "        node_class = SentenceNode\n",
        "   \n",
        "    if type(conf.get(\"root\")) == list:\n",
        "        root = SurrogateNode()\n",
        "        for s in conf.get(\"root\"):\n",
        "            node = node_class.node_from_string(lang=lang, string=s, device=conf.get(\"device\"))\n",
        "            root.add_child(action=s, child=node)\n",
        "    else:\n",
        "        root = node_class.node_from_string(lang=lang, string=conf.get(\"root\", \"\"), device=conf.get(\"device\"))\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    src = os.path.join(repo_root, yaml_path)\n",
        "    dst = os.path.join(output_dir, \"setting.yaml\")\n",
        "    shutil.copy(src, dst)\n",
        "    return generator, conf\n",
        "\n",
        "def generate_and_analyze(generator, conf):\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    generator.plot(**conf.get(\"plot_args\", {}))\n",
        "    generator.analyze()\n",
        "\n",
        "def queue_generations(*args: str):\n",
        "    for yaml_path in args:\n",
        "        generator, conf = read_yaml(yaml_path)\n",
        "        generate_and_analyze(generator, conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KsQZ5Dx_zWtD",
        "outputId": "ad4867f1-023b-4634-ae52-fa0f64488692"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Starting generation...\n",
            "<best reward updated> order: 1, time: 0.00, reward: 0.2395, node: O=C(Cn1cnc2ccccc2c1=O)Nc1ccc(Cl)cc1\n",
            "<best reward updated> order: 3, time: 0.07, reward: 0.3178, node: NC1=NC(=O)N(C/C=C/c2ccccc2F)C[C@H]1c1ccco1\n",
            "<best reward updated> order: 9, time: 0.25, reward: 0.3418, node: O=C(NCCNc1ccc(F)cc1)c1cnc2ccc(F)cc2c1\n",
            "<best reward updated> order: 10, time: 0.29, reward: 0.3419, node: OC[C@@H](O)CCCc1nc2ccccc2s1\n",
            "<best reward updated> order: 14, time: 0.40, reward: 0.3575, node: NS(=O)(=O)c1ccc2c(c1)C=C(O)C2\n",
            "<best reward updated> order: 18, time: 0.52, reward: 0.3839, node: c1ccc(N2CCC(Oc3ccncn3)CC2)cn1\n",
            "<best reward updated> order: 65, time: 2.18, reward: 0.3955, node: NS(=O)(=O)c1ccc(C(=O)[O-])cc1NC(=O)c1csc(-c2ccccc2)n1\n",
            "<best reward updated> order: 82, time: 2.74, reward: 0.4345, node: O[C@@H](c1ccccn1)c1cc(Br)cn1C1CC1\n",
            "generated: 100, time: 3.26, average over 100: 0.2008\n",
            "generated: 200, time: 6.38, average over 100: 0.2370\n",
            "<best reward updated> order: 257, time: 8.10, reward: 0.4429, node: O[C@@H]([C@H]1C[NH+]2CCN1CC2)[C@H]1COc2ccccc21\n",
            "<best reward updated> order: 294, time: 9.21, reward: 0.4690, node: O[C@H]([C@H]1OCOC1(C1CC1)C1CC1)C(F)(F)F\n",
            "generated: 300, time: 9.38, average over 100: 0.2323\n",
            "generated: 400, time: 13.57, average over 100: 0.2978\n",
            "generated: 500, time: 17.72, average over 100: 0.2635\n",
            "<best reward updated> order: 519, time: 18.58, reward: 0.4749, node: O[C@@H](O[C@@H](O)c1ccccc1)c1ccccc1OCc1ccccc1\n",
            "<best reward updated> order: 577, time: 21.08, reward: 0.4792, node: O[C@@H]([C@H]1O[C@H](CO)[C@H](Cl)[C@H]1O)C1CC1\n",
            "generated: 600, time: 21.98, average over 100: 0.2980\n",
            "generated: 700, time: 26.31, average over 100: 0.2718\n",
            "generated: 800, time: 30.38, average over 100: 0.2828\n",
            "generated: 900, time: 34.54, average over 100: 0.2830\n",
            "generated: 1000, time: 38.96, average over 100: 0.2793\n",
            "generated: 1100, time: 43.17, average over 100: 0.2886\n",
            "generated: 1200, time: 47.48, average over 100: 0.3034\n",
            "generated: 1300, time: 51.72, average over 100: 0.3016\n",
            "generated: 1400, time: 55.92, average over 100: 0.2513\n",
            "generated: 1500, time: 59.89, average over 100: 0.2363\n",
            "generated: 1600, time: 64.07, average over 100: 0.3142\n",
            "generated: 1700, time: 68.29, average over 100: 0.2761\n",
            "generated: 1800, time: 72.43, average over 100: 0.2631\n",
            "generated: 1900, time: 76.73, average over 100: 0.2931\n",
            "generated: 2000, time: 81.14, average over 100: 0.2838\n",
            "generated: 2100, time: 85.46, average over 100: 0.2977\n",
            "generated: 2200, time: 89.74, average over 100: 0.2639\n",
            "<best reward updated> order: 2202, time: 89.81, reward: 0.4897, node: O[C@@H](Oc1cccc2ncncc12)c1ccccc1F\n",
            "generated: 2300, time: 93.64, average over 100: 0.3297\n",
            "generated: 2400, time: 97.64, average over 100: 0.3138\n",
            "generated: 2500, time: 102.07, average over 100: 0.3352\n",
            "generated: 2600, time: 106.17, average over 100: 0.3224\n",
            "generated: 2700, time: 110.27, average over 100: 0.3104\n",
            "generated: 2800, time: 114.44, average over 100: 0.3222\n",
            "generated: 2900, time: 118.58, average over 100: 0.2782\n",
            "generated: 3000, time: 122.59, average over 100: 0.2785\n",
            "<best reward updated> order: 3023, time: 123.60, reward: 0.5296, node: O[C@@H](Oc1cccc2ncncc12)C(=O)[O-]\n",
            "generated: 3100, time: 126.61, average over 100: 0.3697\n",
            "<best reward updated> order: 3136, time: 128.11, reward: 0.5474, node: O[C@@H](Oc1cccc2ncncc12)c1cncs1\n",
            "<best reward updated> order: 3175, time: 129.65, reward: 0.5503, node: O[C@@H](Oc1cccc2ncncc12)c1cn[nH]c1Br\n",
            "<best reward updated> order: 3176, time: 129.68, reward: 0.5580, node: O[C@@H](Oc1cccc2ncncc12)c1cn[nH]c1N\n",
            "generated: 3200, time: 130.69, average over 100: 0.4167\n",
            "generated: 3300, time: 134.58, average over 100: 0.4320\n",
            "generated: 3400, time: 138.85, average over 100: 0.4058\n",
            "generated: 3500, time: 142.93, average over 100: 0.4134\n",
            "generated: 3600, time: 147.23, average over 100: 0.3994\n",
            "generated: 3700, time: 151.35, average over 100: 0.4510\n",
            "generated: 3800, time: 155.56, average over 100: 0.3902\n",
            "generated: 3900, time: 159.59, average over 100: 0.3980\n",
            "generated: 4000, time: 163.64, average over 100: 0.3744\n",
            "generated: 4100, time: 167.71, average over 100: 0.4152\n",
            "generated: 4200, time: 172.35, average over 100: 0.4112\n",
            "generated: 4300, time: 176.65, average over 100: 0.4400\n",
            "generated: 4400, time: 181.10, average over 100: 0.4167\n",
            "<best reward updated> order: 4471, time: 184.43, reward: 0.5618, node: O[C@@H](Oc1cccc2ncncc12)c1cccc2cncnc12\n",
            "generated: 4500, time: 185.91, average over 100: 0.4183\n",
            "generated: 4600, time: 190.65, average over 100: 0.4202\n",
            "generated: 4700, time: 195.08, average over 100: 0.4013\n",
            "generated: 4800, time: 199.10, average over 100: 0.4081\n",
            "generated: 4900, time: 203.72, average over 100: 0.4226\n",
            "generated: 5000, time: 208.33, average over 100: 0.4046\n",
            "generated: 5100, time: 212.51, average over 100: 0.4126\n",
            "generated: 5200, time: 216.73, average over 100: 0.4303\n",
            "generated: 5300, time: 221.35, average over 100: 0.4126\n",
            "generated: 5400, time: 225.85, average over 100: 0.4480\n"
          ]
        }
      ],
      "source": [
        "# start generation\n",
        "c1 = \"config/mcts_d_score_replication.yaml\"\n",
        "c2 = \"config/mcts_helm.yaml\"\n",
        "c3 = \"config/mcts_smiles.yaml\"\n",
        "c4 = \"config/model_test.yaml\"\n",
        "c5 = \"config/mcts_d_score.yaml\"\n",
        "c6 = \"config/mcts_j_score.yaml\"\n",
        "generator, conf = read_yaml(c5)\n",
        "generate_and_analyze(generator, conf)\n",
        "# queue_generations(c1, c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#continue search\n",
        "generator.generate(time_limit=conf.get(\"time_limit\") - generator.passed_time, max_generations=conf.get(\"max_generations\") - len(generator.unique_keys))\n",
        "generator.plot(**conf.get(\"plot_args\", {}))\n",
        "generator.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EC6dDxCrF1dA"
      },
      "outputs": [],
      "source": [
        "#save mcts\n",
        "save_path = generator.output_dir() + \"save.mcts\"\n",
        "generator.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load mcts\n",
        "load_dir = \"generation_result/06-26_08-51/\"\n",
        "generator, conf = read_yaml(\"sandbox/\" + load_dir + \"setting.yaml\")\n",
        "generator = Generator.load(load_dir + \"save.mcts\", generator.transition) #TODO: separate notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#time test\n",
        "import cProfile\n",
        "import pstats\n",
        "\n",
        "profiler = cProfile.Profile()\n",
        "profiler.enable()\n",
        "read_yaml(c2)\n",
        "profiler.disable()\n",
        "\n",
        "stats = pstats.Stats(profiler)\n",
        "stats.sort_stats(\"cumtime\").print_stats(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([7.738178695018596,\n",
              "  5.380680492166317,\n",
              "  4.343190079318335,\n",
              "  4.663313149682271,\n",
              "  5.224851127291654,\n",
              "  4.654329008014571,\n",
              "  4.843767364097564,\n",
              "  4.935388081712041,\n",
              "  5.2351610291927955,\n",
              "  -2.3846970086718144,\n",
              "  0.991810044601756,\n",
              "  63.55878775057214,\n",
              "  2.521272632444819,\n",
              "  3.9831675518469654,\n",
              "  0.6139719804089897,\n",
              "  303.283,\n",
              "  1,\n",
              "  1],\n",
              " 0.6487755981901583)"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#DScore test\n",
        "from reward import DScoreReward\n",
        "from node import MolSentenceNode\n",
        "cf = \"config/mcts_d_score.yaml\"\n",
        "generator, conf = read_yaml(cf)\n",
        "string = \"c1sc2ncncc2c1[C@@H](O)c1=nc(C([O-])=O)=nc(N)=n1\"\n",
        "x = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=True, device=\"cpu\")\n",
        "generator.reward.objective_values_and_reward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c1sc2ncncc2c1- 0.055533841252326965\n",
            "c1sc2ncncc2c1/ 0.028348693624138832\n",
            "c1sc2ncncc2c1 0.06410867720842361\n",
            "c1sc2ncncc2c1C 0.4694652259349823\n",
            "c1sc2ncncc2c1F 0.0009618543554097414\n",
            "c1sc2ncncc2c1I 0.0021593605633825064\n",
            "c1sc2ncncc2c1N 0.19565324485301971\n",
            "c1sc2ncncc2c1O 0.017446408048272133\n",
            "c1sc2ncncc2c1S 0.007149592507630587\n",
            "c1sc2ncncc2c1[C@@H] 0.06944021582603455\n",
            "c1sc2ncncc2c1[C@@] 0.002234969986602664\n",
            "c1sc2ncncc2c1[C@H] 0.05132880061864853\n",
            "c1sc2ncncc2c1[C@] 0.0014879098162055016\n",
            "c1sc2ncncc2c1[N-] 0.004273803438991308\n",
            "c1sc2ncncc2c1[O-] 0.012141085229814053\n",
            "c1sc2ncncc2c1c 0.013975519686937332\n",
            "c1sc2ncncc2c1n 0.004290837794542313\n"
          ]
        }
      ],
      "source": [
        "string = \"c1sc2ncncc2c1\"\n",
        "y = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=False, device=\"cpu\")\n",
        "t = generator.transition.transitions_with_probs(y)\n",
        "for action, node, prob in t:\n",
        "    print(node, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([11.004699999999985, 2.7979856545812734, 0], 0.8645154119818951)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#JScore test\n",
        "from reward import DScoreReward\n",
        "from node import MolSentenceNode\n",
        "cf = \"config/mcts_j_score.yaml\"\n",
        "generator, conf = read_yaml(cf)\n",
        "string = \"O=C(Nc1cc(Nc2c(Cl)cccc2NCc2ccc(Cl)cc2Cl)ccc1C1=CCCCC1)c1cc(F)cc(Cl)c1\"\n",
        "x = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=True, device=\"cpu\")\n",
        "generator.reward.objective_values_and_reward(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
