{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add path (for local)\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import torch\n",
        "from typing import Any\n",
        "import yaml\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language, MolLanguage\n",
        "from node import SurrogateNode, SentenceNode, MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "\n",
        "RDLogger.DisableLog('rdApp.*') # use debug: true to log invalid mols\n",
        "\n",
        "def read_yaml(yaml_path: str) -> tuple[Generator, dict[str, Any]]:\n",
        "    with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "        conf = yaml.safe_load(f)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, file_level=file_level)\n",
        "\n",
        "    if \"seed\" in conf:\n",
        "        seed = conf[\"seed\"]\n",
        "    else:\n",
        "        seed = int(time.time()) % (2**32)\n",
        "    logger.info(\"seed: \" + str(seed))\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "    transition_args = conf.get(\"transition_args\", {})\n",
        "    if \"model_dir\" in transition_args:\n",
        "        transition_args[\"model_dir\"] = os.path.join(repo_root, transition_args[\"model_dir\"])\n",
        "    lang_path = conf.get(\"lang_path\")\n",
        "    if lang_path is None:\n",
        "        lang_name = os.path.basename(os.path.normpath(transition_args[\"model_dir\"])) + \".lang\"\n",
        "        lang_path = add_sep(transition_args[\"model_dir\"]) + lang_name\n",
        "    lang = Language.load(lang_path)\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "\n",
        "    reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "    reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "    \n",
        "    if \"policy_class\" in conf:\n",
        "        policy_class = class_from_package(\"policy\", conf.get(\"policy_class\"))\n",
        "        policy = policy_class(**conf.get(\"policy_args\", {}))\n",
        "        generator_args[\"policy\"] = policy\n",
        "\n",
        "    filter_settings = conf.get(\"filters\", [])\n",
        "    filters = []\n",
        "    for s in filter_settings:\n",
        "        filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "        filters.append(filter_class(**s))\n",
        "\n",
        "    if \"node_class\" in conf:\n",
        "        node_class = class_from_package(\"node\", conf.get(\"node_class\"))\n",
        "    elif issubclass(lang.__class__, MolLanguage):\n",
        "        node_class = MolSentenceNode\n",
        "    elif issubclass(lang.__class__, Language):\n",
        "        node_class = SentenceNode\n",
        "    if node_class == MolSentenceNode:\n",
        "        MolSentenceNode.use_canonical_smiles_as_key = conf.get(\"use_canonical_smiles_as_key\", True)\n",
        "   \n",
        "    if type(conf.get(\"root\")) == list:\n",
        "        root = SurrogateNode()\n",
        "        for s in conf.get(\"root\"):\n",
        "            node = node_class.node_from_key(lang=lang, string=s, device=conf.get(\"device\"))\n",
        "            root.add_child(action=s, child=node)\n",
        "    else:\n",
        "        root = node_class.node_from_key(lang=lang, string=conf.get(\"root\", \"\"), device=conf.get(\"device\"))\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    src = os.path.join(repo_root, yaml_path)\n",
        "    dst = os.path.join(output_dir, \"setting.yaml\")\n",
        "    shutil.copy(src, dst)\n",
        "    return generator, conf\n",
        "\n",
        "def generate_and_analyze(generator, conf):\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    generator.plot(**conf.get(\"plot_args\", {}))\n",
        "    generator.analyze()\n",
        "\n",
        "def queue_generations(*args: str):\n",
        "    for yaml_path in args:\n",
        "        generator, conf = read_yaml(yaml_path)\n",
        "        generate_and_analyze(generator, conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KsQZ5Dx_zWtD",
        "outputId": "ad4867f1-023b-4634-ae52-fa0f64488692"
      },
      "outputs": [],
      "source": [
        "# start generation\n",
        "c1 = \"config/mcts_d_score_replication.yaml\"\n",
        "c2 = \"config/mcts_helm.yaml\"\n",
        "c3 = \"config/mcts_smiles.yaml\"\n",
        "c4 = \"config/model_test.yaml\"\n",
        "c5 = \"config/mcts_d_score.yaml\"\n",
        "c6 = \"config/mcts_j_score.yaml\"\n",
        "generator, conf = read_yaml(c2)\n",
        "generate_and_analyze(generator, conf)\n",
        "# queue_generations(c1, c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = generator.transition.rollout(generator.root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[13, 17, 15, 17, 17, 21, 17,  1, 15, 22,  2, 17, 24, 17, 60,  5, 61, 61,\n",
              "         60,  6, 63, 60,  7, 60, 60, 60, 60, 60,  7, 61,  5,  6, 14]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = generator.transition.transitions_with_probs(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#continue search\n",
        "generator.generate(time_limit=conf.get(\"time_limit\") - generator.passed_time, max_generations=conf.get(\"max_generations\") - len(generator.unique_keys))\n",
        "generator.plot(**conf.get(\"plot_args\", {}))\n",
        "generator.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EC6dDxCrF1dA"
      },
      "outputs": [],
      "source": [
        "#save mcts\n",
        "save_path = generator.output_dir() + \"save.mcts\"\n",
        "generator.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load generator and yaml\n",
        "load_dir = \"generation_result/06-26_08-51/\"\n",
        "generator, conf = read_yaml(\"sandbox/\" + load_dir + \"setting.yaml\")\n",
        "generator = Generator.load(load_dir + \"save.mcts\", generator.transition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#time test\n",
        "import cProfile\n",
        "import pstats\n",
        "\n",
        "profiler = cProfile.Profile()\n",
        "profiler.enable()\n",
        "read_yaml(c2)\n",
        "profiler.disable()\n",
        "\n",
        "stats = pstats.Stats(profiler)\n",
        "stats.sort_stats(\"cumtime\").print_stats(100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
