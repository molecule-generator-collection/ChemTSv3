{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#for local\n",
        "import sys\n",
        "repo_root = \"../\"\n",
        "if repo_root not in sys.path:\n",
        "    sys.path.insert(0, repo_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from datetime import datetime\n",
        "import importlib\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "from typing import Any\n",
        "import yaml\n",
        "from rdkit import RDLogger\n",
        "from generator import Generator\n",
        "from language import Language, MolLanguage\n",
        "from node import SurrogateNode, SentenceNode, MolSentenceNode\n",
        "from utils import add_sep, class_from_package, make_logger\n",
        "\n",
        "RDLogger.DisableLog('rdApp.*') # use debug: true to log invalid mols\n",
        "\n",
        "def read_yaml(yaml_path: str) -> tuple[Generator, dict[str, Any]]:\n",
        "    with open(os.path.join(repo_root, yaml_path)) as f:\n",
        "        conf = yaml.safe_load(f)\n",
        "\n",
        "    output_dir=os.path.join(repo_root, \"sandbox\", conf[\"output_dir\"], datetime.now().strftime(\"%m-%d_%H-%M\")) + os.sep\n",
        "    file_level = logging.DEBUG if conf.get(\"debug\") else logging.INFO\n",
        "    logger = make_logger(output_dir, file_level=file_level)\n",
        "    generator_args = conf.get(\"generator_args\", {})\n",
        "\n",
        "    transition_args = conf.get(\"transition_args\", {})\n",
        "    if \"model_dir\" in transition_args:\n",
        "        transition_args[\"model_dir\"] = os.path.join(repo_root, transition_args[\"model_dir\"])\n",
        "    lang_path = conf.get(\"lang_path\")\n",
        "    if lang_path is None:\n",
        "        lang_name = os.path.basename(os.path.normpath(transition_args[\"model_dir\"])) + \".lang\"\n",
        "        lang_path = add_sep(transition_args[\"model_dir\"]) + lang_name\n",
        "    lang = Language.load(lang_path)\n",
        "    transition_class = class_from_package(\"transition\", conf[\"transition_class\"])\n",
        "    transition = transition_class(lang=lang, logger=logger, device=conf.get(\"device\"), **transition_args)\n",
        "\n",
        "    reward_class = class_from_package(\"reward\", conf.get(\"reward_class\"))\n",
        "    reward = reward_class(**conf.get(\"reward_args\", {}))\n",
        "    \n",
        "    if \"policy_class\" in conf:\n",
        "        policy_class = class_from_package(\"policy\", conf.get(\"policy_class\"))\n",
        "        policy = policy_class(**conf.get(\"policy_args\", {}))\n",
        "        generator_args[\"policy\"] = policy\n",
        "\n",
        "    filter_settings = conf.get(\"filters\", [])\n",
        "    filters = []\n",
        "    for s in filter_settings:\n",
        "        filter_class = class_from_package(\"filter\", s.pop(\"filter_class\"))\n",
        "        filters.append(filter_class(**s))\n",
        "\n",
        "    if \"node_class\" in conf:\n",
        "        node_class = class_from_package(\"node\", conf.get(\"node_class\"))\n",
        "    elif issubclass(lang.__class__, MolLanguage):\n",
        "        node_class = MolSentenceNode\n",
        "    elif issubclass(lang.__class__, Language):\n",
        "        node_class = SentenceNode\n",
        "   \n",
        "    if type(conf.get(\"root\")) == list:\n",
        "        root = SurrogateNode()\n",
        "        for s in conf.get(\"root\"):\n",
        "            node = node_class.node_from_string(lang=lang, string=s, device=conf.get(\"device\"))\n",
        "            root.add_child(action=s, child=node)\n",
        "    else:\n",
        "        root = node_class.node_from_string(lang=lang, string=conf.get(\"root\", \"\"), device=conf.get(\"device\"))\n",
        "    \n",
        "    generator_class = class_from_package(\"generator\", conf.get(\"generator_class\", \"MCTS\"))\n",
        "    generator = generator_class(root=root, transition=transition, reward=reward, filters=filters, output_dir=output_dir, logger=logger, **generator_args)\n",
        "\n",
        "    src = os.path.join(repo_root, yaml_path)\n",
        "    dst = os.path.join(output_dir, \"setting.yaml\")\n",
        "    shutil.copy(src, dst)\n",
        "    return generator, conf\n",
        "\n",
        "def generate_and_analyze(generator, conf):\n",
        "    generator.generate(time_limit=conf.get(\"time_limit\"), max_generations=conf.get(\"max_generations\"))\n",
        "    generator.plot(**conf.get(\"plot_args\", {}))\n",
        "    generator.analyze()\n",
        "\n",
        "def queue_generations(*args: str):\n",
        "    for yaml_path in args:\n",
        "        generator, conf = read_yaml(yaml_path)\n",
        "        generate_and_analyze(generator, conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KsQZ5Dx_zWtD",
        "outputId": "ad4867f1-023b-4634-ae52-fa0f64488692"
      },
      "outputs": [],
      "source": [
        "c1 = \"config/mcts_d_score_repli_soft.yaml\"\n",
        "c2 = \"config/mcts_helm.yaml\"\n",
        "c3 = \"config/mcts_smiles.yaml\"\n",
        "c4 = \"config/model_test.yaml\"\n",
        "c5 = \"config/mcts_d_score.yaml\"\n",
        "c6 = \"config/mcts_j_score.yaml\"\n",
        "generator, conf = read_yaml(c1)\n",
        "generate_and_analyze(generator, conf)\n",
        "# queue_generations(c1, c2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#continue search\n",
        "generator.generate(time_limit=conf.get(\"time_limit\") - generator.passed_time, max_generations=conf.get(\"max_generations\") - len(generator.unique_keys))\n",
        "generator.plot(**conf.get(\"plot_args\", {}))\n",
        "generator.analyze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC6dDxCrF1dA"
      },
      "outputs": [],
      "source": [
        "#save mcts\n",
        "save_path = generator.output_dir() + \"save.mcts\"\n",
        "generator.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load mcts test\n",
        "load_path = generator.output_dir() + \"save.mcts\"\n",
        "generator = MCTS.load(load_path, generator.transition) #TODO: separate notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#time test\n",
        "import cProfile\n",
        "import pstats\n",
        "\n",
        "profiler = cProfile.Profile()\n",
        "profiler.enable()\n",
        "read_yaml(c2)\n",
        "profiler.disable()\n",
        "\n",
        "stats = pstats.Stats(profiler)\n",
        "stats.sort_stats(\"cumtime\").print_stats(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([7.738178695018596,\n",
              "  5.380680492166317,\n",
              "  4.343190079318335,\n",
              "  4.663313149682271,\n",
              "  5.224851127291654,\n",
              "  4.654329008014571,\n",
              "  4.843767364097564,\n",
              "  4.935388081712041,\n",
              "  5.2351610291927955,\n",
              "  -2.3846970086718144,\n",
              "  0.991810044601756,\n",
              "  63.55878775057214,\n",
              "  2.521272632444819,\n",
              "  3.9831675518469654,\n",
              "  0.6139719804089897,\n",
              "  303.283,\n",
              "  1,\n",
              "  1],\n",
              " 0.6487755981901583)"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#DScore test\n",
        "from reward import DScoreReward\n",
        "from node import MolSentenceNode\n",
        "cf = \"config/mcts_d_score.yaml\"\n",
        "generator, conf = read_yaml(cf)\n",
        "string = \"c1sc2ncncc2c1[C@@H](O)c1=nc(C([O-])=O)=nc(N)=n1\"\n",
        "x = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=True, device=\"cpu\")\n",
        "generator.reward.objective_values_and_reward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c1sc2ncncc2c1- 0.055533841252326965\n",
            "c1sc2ncncc2c1/ 0.028348693624138832\n",
            "c1sc2ncncc2c1 0.06410867720842361\n",
            "c1sc2ncncc2c1C 0.4694652259349823\n",
            "c1sc2ncncc2c1F 0.0009618543554097414\n",
            "c1sc2ncncc2c1I 0.0021593605633825064\n",
            "c1sc2ncncc2c1N 0.19565324485301971\n",
            "c1sc2ncncc2c1O 0.017446408048272133\n",
            "c1sc2ncncc2c1S 0.007149592507630587\n",
            "c1sc2ncncc2c1[C@@H] 0.06944021582603455\n",
            "c1sc2ncncc2c1[C@@] 0.002234969986602664\n",
            "c1sc2ncncc2c1[C@H] 0.05132880061864853\n",
            "c1sc2ncncc2c1[C@] 0.0014879098162055016\n",
            "c1sc2ncncc2c1[N-] 0.004273803438991308\n",
            "c1sc2ncncc2c1[O-] 0.012141085229814053\n",
            "c1sc2ncncc2c1c 0.013975519686937332\n",
            "c1sc2ncncc2c1n 0.004290837794542313\n"
          ]
        }
      ],
      "source": [
        "string = \"c1sc2ncncc2c1\"\n",
        "y = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=False, device=\"cpu\")\n",
        "t = generator.transition.transitions_with_probs(y)\n",
        "for action, node, prob in t:\n",
        "    print(node, prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([11.004699999999985, 2.7979856545812734, 0], 0.8645154119818951)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#JScore test\n",
        "from reward import DScoreReward\n",
        "from node import MolSentenceNode\n",
        "cf = \"config/mcts_j_score.yaml\"\n",
        "generator, conf = read_yaml(cf)\n",
        "string = \"O=C(Nc1cc(Nc2c(Cl)cccc2NCc2ccc(Cl)cc2Cl)ccc1C1=CCCCC1)c1cc(F)cc(Cl)c1\"\n",
        "x = MolSentenceNode.node_from_string(lang=generator.transition.lang, string=string, include_eos=True, device=\"cpu\")\n",
        "generator.reward.objective_values_and_reward(x)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "v3-forge",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
